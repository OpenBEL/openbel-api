[2015-08-13 09:06:54,479] INFO KafkaConfig values: 
	log.roll.hours = 168
	controlled.shutdown.max.retries = 3
	inter.broker.protocol.version = 0.8.3.X
	log.cleaner.threads = 1
	zookeeper.connection.timeout.ms = 6000
	log.preallocate = false
	offsets.load.buffer.size = 5242880
	security.inter.broker.protocol = PLAINTEXT
	controller.socket.timeout.ms = 30000
	zookeeper.session.timeout.ms = 6000
	log.cleaner.enable = false
	controlled.shutdown.enable = true
	offsets.topic.num.partitions = 50
	num.recovery.threads.per.data.dir = 1
	background.threads = 10
	unclean.leader.election.enable = true
	message.max.bytes = 1000012
	log.cleaner.backoff.ms = 15000
	replica.lag.time.max.ms = 10000
	log.roll.jitter.hours = 0
	auto.create.topics.enable = true
	log.retention.check.interval.ms = 300000
	zookeeper.sync.time.ms = 2000
	offsets.topic.compression.codec = 0
	log.cleaner.io.buffer.load.factor = 0.9
	replica.fetch.max.bytes = 1048576
	log.retention.hours = 168
	log.cleaner.delete.retention.ms = 86400000
	log.dirs = /home/tony/projects/openbel/openbel-server/out/kafka-logs
	log.index.size.max.bytes = 10485760
	fetch.purgatory.purge.interval.requests = 1000
	log.retention.minutes = null
	connections.max.idle.ms = 600000
	log.cleaner.min.cleanable.ratio = 0.5
	offsets.commit.timeout.ms = 5000
	offsets.retention.minutes = 1440
	max.connections.per.ip = 2147483647
	log.retention.bytes = -1
	offset.metadata.max.bytes = 4096
	replica.fetch.wait.max.ms = 500
	metrics.num.samples = 2
	leader.imbalance.check.interval.seconds = 300
	port = 9092
	offsets.retention.check.interval.ms = 600000
	log.roll.jitter.ms = null
	reserved.broker.max.id = 1000
	log.cleaner.dedupe.buffer.size = 524288000
	replica.fetch.backoff.ms = 1000
	log.segment.bytes = 1073741824
	advertised.host.name = null
	log.cleaner.io.buffer.size = 524288
	log.dir = /tmp/kafka-logs
	min.insync.replicas = 1
	producer.purgatory.purge.interval.requests = 1000
	controlled.shutdown.retry.backoff.ms = 5000
	socket.receive.buffer.bytes = 102400
	log.segment.delete.delay.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.offset.checkpoint.interval.ms = 60000
	consumer.min.session.timeout.ms = 6000
	num.partitions = 1
	num.io.threads = 8
	leader.imbalance.per.broker.percentage = 10
	num.network.threads = 3
	socket.request.max.bytes = 104857600
	queued.max.requests = 500
	zookeeper.connect = localhost:2181
	offsets.topic.replication.factor = 3
	log.roll.ms = null
	replica.socket.timeout.ms = 30000
	offsets.topic.segment.bytes = 104857600
	replica.high.watermark.checkpoint.interval.ms = 5000
	broker.id = 0
	listeners = null
	log.flush.interval.messages = 9223372036854775807
	log.retention.ms = null
	socket.send.buffer.bytes = 102400
	offsets.commit.required.acks = -1
	log.flush.interval.ms = null
	consumer.max.session.timeout.ms = 30000
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	num.replica.fetchers = 1
	default.replication.factor = 1
	metrics.sample.window.ms = 1000
	advertised.listeners = null
	replica.socket.receive.buffer.bytes = 65536
	auto.leader.rebalance.enable = true
	delete.topic.enable = false
	log.index.interval.bytes = 4096
	host.name = 
	metric.reporters = []
	compression.type = producer
	advertised.port = null
	max.connections.per.ip.overrides = 
	replica.fetch.min.bytes = 1
	log.cleanup.policy = delete
 (kafka.server.KafkaConfig)
[2015-08-13 09:06:54,598] INFO starting (kafka.server.KafkaServer)
[2015-08-13 09:06:54,601] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2015-08-13 09:06:54,862] INFO Loading logs. (kafka.log.LogManager)
[2015-08-13 09:06:54,916] WARN Found an corrupted index file, /home/tony/projects/openbel/openbel-server/out/kafka-logs/evidence-0/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[2015-08-13 09:06:57,596] INFO Recovering unflushed segment 0 in log evidence-0. (kafka.log.Log)
[2015-08-13 09:06:59,328] INFO Completed load of log evidence-0 with log end offset 1253856 (kafka.log.Log)
[2015-08-13 09:06:59,342] INFO Logs loading complete. (kafka.log.LogManager)
[2015-08-13 09:06:59,343] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2015-08-13 09:06:59,349] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2015-08-13 09:06:59,406] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2015-08-13 09:06:59,408] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2015-08-13 09:06:59,439] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:06:59,440] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:06:59,650] INFO [ConsumerCoordinator 0]: Starting up. (kafka.coordinator.ConsumerCoordinator)
[2015-08-13 09:06:59,652] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:06:59,653] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:06:59,655] INFO [ConsumerCoordinator 0]: Startup complete. (kafka.coordinator.ConsumerCoordinator)
[2015-08-13 09:06:59,659] INFO [Offset Manager on Broker 0]: Removed 0 expired offsets in 10 milliseconds. (kafka.server.OffsetManager)
[2015-08-13 09:06:59,674] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2015-08-13 09:06:59,715] INFO conflict in /brokers/ids/0 data: {"jmx_port":-1,"timestamp":"1439471219685","endpoints":["PLAINTEXT://localhost.localdomain:9092"],"host":"localhost.localdomain","version":2,"port":9092} stored data: {"jmx_port":-1,"timestamp":"1439470712036","endpoints":["PLAINTEXT://localhost.localdomain:9092"],"host":"localhost.localdomain","version":2,"port":9092} (kafka.utils.ZkUtils$)
[2015-08-13 09:06:59,764] INFO I wrote this conflicted ephemeral node [{"jmx_port":-1,"timestamp":"1439471219685","endpoints":["PLAINTEXT://localhost.localdomain:9092"],"host":"localhost.localdomain","version":2,"port":9092}] at /brokers/ids/0 a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)
[2015-08-13 09:07:03,029] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2015-08-13 09:07:03,204] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2015-08-13 09:07:03,739] ERROR [KafkaApi-0] error when handling request Name: TopicMetadataRequest; Version: 0; CorrelationId: 3500; ClientId: rdkafka; Topics: evidence (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 1 larger than available brokers: 0
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:76)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:235)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:461)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:444)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:93)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:444)
	at kafka.server.KafkaApis.handleTopicMetadataRequest(KafkaApis.scala:486)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:59)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2015-08-13 09:07:03,778] ERROR [KafkaApi-0] error when handling request Name: TopicMetadataRequest; Version: 0; CorrelationId: 64; ClientId: rdkafka; Topics: evidence (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 1 larger than available brokers: 0
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:76)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:235)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:461)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:444)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:93)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:444)
	at kafka.server.KafkaApis.handleTopicMetadataRequest(KafkaApis.scala:486)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:59)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2015-08-13 09:07:04,714] ERROR [KafkaApi-0] error when handling request Name: TopicMetadataRequest; Version: 0; CorrelationId: 5197; ClientId: rdkafka; Topics: evidence (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 1 larger than available brokers: 0
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:76)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:235)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:461)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:444)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:93)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:444)
	at kafka.server.KafkaApis.handleTopicMetadataRequest(KafkaApis.scala:486)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:59)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2015-08-13 09:07:04,778] ERROR [KafkaApi-0] error when handling request Name: TopicMetadataRequest; Version: 0; CorrelationId: 36; ClientId: rdkafka; Topics: evidence (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 1 larger than available brokers: 0
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:76)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:235)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:461)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:444)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:93)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:444)
	at kafka.server.KafkaApis.handleTopicMetadataRequest(KafkaApis.scala:486)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:59)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2015-08-13 09:07:05,776] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(localhost.localdomain,9092,PLAINTEXT) (kafka.utils.ZkUtils$)
[2015-08-13 09:07:05,785] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2015-08-13 09:07:05,984] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [evidence,0] (kafka.server.ReplicaFetcherManager)
[2015-08-13 09:07:06,008] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [evidence,0] (kafka.server.ReplicaFetcherManager)
[2015-08-13 09:07:12,622] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2015-08-13 09:07:12,625] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[2015-08-13 09:07:47,492] INFO KafkaConfig values: 
	log.roll.hours = 168
	controlled.shutdown.max.retries = 3
	inter.broker.protocol.version = 0.8.3.X
	log.cleaner.threads = 1
	zookeeper.connection.timeout.ms = 6000
	log.preallocate = false
	offsets.load.buffer.size = 5242880
	security.inter.broker.protocol = PLAINTEXT
	controller.socket.timeout.ms = 30000
	zookeeper.session.timeout.ms = 6000
	log.cleaner.enable = false
	controlled.shutdown.enable = true
	offsets.topic.num.partitions = 50
	num.recovery.threads.per.data.dir = 1
	background.threads = 10
	unclean.leader.election.enable = true
	message.max.bytes = 1000012
	log.cleaner.backoff.ms = 15000
	replica.lag.time.max.ms = 10000
	log.roll.jitter.hours = 0
	auto.create.topics.enable = true
	log.retention.check.interval.ms = 300000
	zookeeper.sync.time.ms = 2000
	offsets.topic.compression.codec = 0
	log.cleaner.io.buffer.load.factor = 0.9
	replica.fetch.max.bytes = 1048576
	log.retention.hours = 168
	log.cleaner.delete.retention.ms = 86400000
	log.dirs = /home/tony/projects/openbel/openbel-server/out/kafka-logs
	log.index.size.max.bytes = 10485760
	fetch.purgatory.purge.interval.requests = 1000
	log.retention.minutes = null
	connections.max.idle.ms = 600000
	log.cleaner.min.cleanable.ratio = 0.5
	offsets.commit.timeout.ms = 5000
	offsets.retention.minutes = 1440
	max.connections.per.ip = 2147483647
	log.retention.bytes = -1
	offset.metadata.max.bytes = 4096
	replica.fetch.wait.max.ms = 500
	metrics.num.samples = 2
	leader.imbalance.check.interval.seconds = 300
	port = 9092
	offsets.retention.check.interval.ms = 600000
	log.roll.jitter.ms = null
	reserved.broker.max.id = 1000
	log.cleaner.dedupe.buffer.size = 524288000
	replica.fetch.backoff.ms = 1000
	log.segment.bytes = 1073741824
	advertised.host.name = null
	log.cleaner.io.buffer.size = 524288
	log.dir = /tmp/kafka-logs
	min.insync.replicas = 1
	producer.purgatory.purge.interval.requests = 1000
	controlled.shutdown.retry.backoff.ms = 5000
	socket.receive.buffer.bytes = 102400
	log.segment.delete.delay.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.offset.checkpoint.interval.ms = 60000
	consumer.min.session.timeout.ms = 6000
	num.partitions = 1
	num.io.threads = 8
	leader.imbalance.per.broker.percentage = 10
	num.network.threads = 3
	socket.request.max.bytes = 104857600
	queued.max.requests = 500
	zookeeper.connect = localhost:2181
	offsets.topic.replication.factor = 3
	log.roll.ms = null
	replica.socket.timeout.ms = 30000
	offsets.topic.segment.bytes = 104857600
	replica.high.watermark.checkpoint.interval.ms = 5000
	broker.id = 0
	listeners = null
	log.flush.interval.messages = 9223372036854775807
	log.retention.ms = null
	socket.send.buffer.bytes = 102400
	offsets.commit.required.acks = -1
	log.flush.interval.ms = null
	consumer.max.session.timeout.ms = 30000
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	num.replica.fetchers = 1
	default.replication.factor = 1
	metrics.sample.window.ms = 1000
	advertised.listeners = null
	replica.socket.receive.buffer.bytes = 65536
	auto.leader.rebalance.enable = true
	delete.topic.enable = false
	log.index.interval.bytes = 4096
	host.name = 
	metric.reporters = []
	compression.type = producer
	advertised.port = null
	max.connections.per.ip.overrides = 
	replica.fetch.min.bytes = 1
	log.cleanup.policy = delete
 (kafka.server.KafkaConfig)
[2015-08-13 09:07:47,616] INFO starting (kafka.server.KafkaServer)
[2015-08-13 09:07:47,620] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2015-08-13 09:07:47,831] INFO Loading logs. (kafka.log.LogManager)
[2015-08-13 09:07:47,874] WARN Found an corrupted index file, /home/tony/projects/openbel/openbel-server/out/kafka-logs/evidence-0/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[2015-08-13 09:07:49,992] INFO Recovering unflushed segment 0 in log evidence-0. (kafka.log.Log)
[2015-08-13 09:07:52,109] INFO Completed load of log evidence-0 with log end offset 1253856 (kafka.log.Log)
[2015-08-13 09:07:52,121] INFO Logs loading complete. (kafka.log.LogManager)
[2015-08-13 09:07:52,121] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2015-08-13 09:07:52,126] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2015-08-13 09:07:52,181] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2015-08-13 09:07:52,182] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2015-08-13 09:07:52,211] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:07:52,212] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:07:52,396] INFO [ConsumerCoordinator 0]: Starting up. (kafka.coordinator.ConsumerCoordinator)
[2015-08-13 09:07:52,400] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:07:52,401] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:07:52,403] INFO [ConsumerCoordinator 0]: Startup complete. (kafka.coordinator.ConsumerCoordinator)
[2015-08-13 09:07:52,407] INFO [Offset Manager on Broker 0]: Removed 0 expired offsets in 12 milliseconds. (kafka.server.OffsetManager)
[2015-08-13 09:07:52,421] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2015-08-13 09:07:52,470] INFO conflict in /brokers/ids/0 data: {"jmx_port":-1,"timestamp":"1439471272435","endpoints":["PLAINTEXT://localhost.localdomain:9092"],"host":"localhost.localdomain","version":2,"port":9092} stored data: {"jmx_port":-1,"timestamp":"1439471219685","endpoints":["PLAINTEXT://localhost.localdomain:9092"],"host":"localhost.localdomain","version":2,"port":9092} (kafka.utils.ZkUtils$)
[2015-08-13 09:07:52,537] INFO I wrote this conflicted ephemeral node [{"jmx_port":-1,"timestamp":"1439471272435","endpoints":["PLAINTEXT://localhost.localdomain:9092"],"host":"localhost.localdomain","version":2,"port":9092}] at /brokers/ids/0 a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)
[2015-08-13 09:07:54,075] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2015-08-13 09:07:54,250] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2015-08-13 09:07:54,306] ERROR [KafkaApi-0] error when handling request Name: TopicMetadataRequest; Version: 0; CorrelationId: 3789; ClientId: rdkafka; Topics: evidence (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 1 larger than available brokers: 0
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:76)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:235)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:461)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:444)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:93)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:444)
	at kafka.server.KafkaApis.handleTopicMetadataRequest(KafkaApis.scala:486)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:59)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2015-08-13 09:07:54,306] ERROR [KafkaApi-0] error when handling request Name: TopicMetadataRequest; Version: 0; CorrelationId: 72; ClientId: rdkafka; Topics: evidence (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 1 larger than available brokers: 0
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:76)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:235)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:461)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:444)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:93)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:444)
	at kafka.server.KafkaApis.handleTopicMetadataRequest(KafkaApis.scala:486)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:59)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2015-08-13 09:07:55,247] ERROR [KafkaApi-0] error when handling request Name: TopicMetadataRequest; Version: 0; CorrelationId: 42; ClientId: rdkafka; Topics: evidence (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 1 larger than available brokers: 0
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:76)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:235)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:461)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:444)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:93)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:444)
	at kafka.server.KafkaApis.handleTopicMetadataRequest(KafkaApis.scala:486)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:59)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2015-08-13 09:07:55,247] ERROR [KafkaApi-0] error when handling request Name: TopicMetadataRequest; Version: 0; CorrelationId: 5202; ClientId: rdkafka; Topics: evidence (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 1 larger than available brokers: 0
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:76)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:235)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:461)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:444)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:93)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:444)
	at kafka.server.KafkaApis.handleTopicMetadataRequest(KafkaApis.scala:486)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:59)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2015-08-13 09:07:56,252] ERROR [KafkaApi-0] error when handling request Name: TopicMetadataRequest; Version: 0; CorrelationId: 43; ClientId: rdkafka; Topics: evidence (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 1 larger than available brokers: 0
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:76)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:235)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:461)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:444)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:93)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:444)
	at kafka.server.KafkaApis.handleTopicMetadataRequest(KafkaApis.scala:486)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:59)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2015-08-13 09:07:56,311] ERROR [KafkaApi-0] error when handling request Name: TopicMetadataRequest; Version: 0; CorrelationId: 73; ClientId: rdkafka; Topics: evidence (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 1 larger than available brokers: 0
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:76)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:235)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:461)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:444)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:93)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:444)
	at kafka.server.KafkaApis.handleTopicMetadataRequest(KafkaApis.scala:486)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:59)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2015-08-13 09:07:57,253] ERROR [KafkaApi-0] error when handling request Name: TopicMetadataRequest; Version: 0; CorrelationId: 5203; ClientId: rdkafka; Topics: evidence (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 1 larger than available brokers: 0
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:76)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:235)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:461)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:444)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:93)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:444)
	at kafka.server.KafkaApis.handleTopicMetadataRequest(KafkaApis.scala:486)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:59)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2015-08-13 09:07:57,256] ERROR [KafkaApi-0] error when handling request Name: TopicMetadataRequest; Version: 0; CorrelationId: 44; ClientId: rdkafka; Topics: evidence (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 1 larger than available brokers: 0
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:76)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:235)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:461)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:444)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:93)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:444)
	at kafka.server.KafkaApis.handleTopicMetadataRequest(KafkaApis.scala:486)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:59)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2015-08-13 09:07:58,256] ERROR [KafkaApi-0] error when handling request Name: TopicMetadataRequest; Version: 0; CorrelationId: 5205; ClientId: rdkafka; Topics: evidence (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 1 larger than available brokers: 0
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:76)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:235)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:461)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:444)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:93)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:444)
	at kafka.server.KafkaApis.handleTopicMetadataRequest(KafkaApis.scala:486)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:59)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2015-08-13 09:07:58,313] ERROR [KafkaApi-0] error when handling request Name: TopicMetadataRequest; Version: 0; CorrelationId: 3791; ClientId: rdkafka; Topics: evidence (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 1 larger than available brokers: 0
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:76)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:235)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:461)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:444)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:93)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:444)
	at kafka.server.KafkaApis.handleTopicMetadataRequest(KafkaApis.scala:486)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:59)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2015-08-13 09:07:58,548] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(localhost.localdomain,9092,PLAINTEXT) (kafka.utils.ZkUtils$)
[2015-08-13 09:07:58,561] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2015-08-13 09:07:58,685] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [evidence,0] (kafka.server.ReplicaFetcherManager)
[2015-08-13 09:07:58,711] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [evidence,0] (kafka.server.ReplicaFetcherManager)
[2015-08-13 09:08:04,231] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2015-08-13 09:08:04,232] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[2015-08-13 09:08:04,288] INFO [Kafka Server 0], Controlled shutdown succeeded (kafka.server.KafkaServer)
[2015-08-13 09:08:04,292] INFO [Socket Server on Broker 0], Shutting down (kafka.network.SocketServer)
[2015-08-13 09:08:04,300] INFO [Socket Server on Broker 0], Shutdown completed (kafka.network.SocketServer)
[2015-08-13 09:08:04,302] INFO [Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2015-08-13 09:08:04,305] INFO [Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2015-08-13 09:08:04,309] INFO [Replica Manager on Broker 0]: Shutting down (kafka.server.ReplicaManager)
[2015-08-13 09:08:04,309] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2015-08-13 09:08:04,312] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2015-08-13 09:08:04,313] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:08:04,382] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:08:04,382] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:08:04,383] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:08:04,424] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:08:04,424] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:08:04,436] INFO [Replica Manager on Broker 0]: Shut down completely (kafka.server.ReplicaManager)
[2015-08-13 09:08:04,438] INFO Shutting down. (kafka.log.LogManager)
[2015-08-13 09:08:04,471] INFO Shutdown complete. (kafka.log.LogManager)
[2015-08-13 09:08:04,472] INFO [ConsumerCoordinator 0]: Shutting down. (kafka.coordinator.ConsumerCoordinator)
[2015-08-13 09:08:04,474] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:08:04,614] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:08:04,614] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:08:04,615] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:08:04,814] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:08:04,814] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:08:04,817] INFO [ConsumerCoordinator 0]: Shutdown complete. (kafka.coordinator.ConsumerCoordinator)
[2015-08-13 09:08:05,221] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2015-08-13 09:08:07,171] INFO KafkaConfig values: 
	log.roll.hours = 168
	controlled.shutdown.max.retries = 3
	inter.broker.protocol.version = 0.8.3.X
	log.cleaner.threads = 1
	zookeeper.connection.timeout.ms = 6000
	log.preallocate = false
	offsets.load.buffer.size = 5242880
	security.inter.broker.protocol = PLAINTEXT
	controller.socket.timeout.ms = 30000
	zookeeper.session.timeout.ms = 6000
	log.cleaner.enable = false
	controlled.shutdown.enable = true
	offsets.topic.num.partitions = 50
	num.recovery.threads.per.data.dir = 1
	background.threads = 10
	unclean.leader.election.enable = true
	message.max.bytes = 1000012
	log.cleaner.backoff.ms = 15000
	replica.lag.time.max.ms = 10000
	log.roll.jitter.hours = 0
	auto.create.topics.enable = true
	log.retention.check.interval.ms = 300000
	zookeeper.sync.time.ms = 2000
	offsets.topic.compression.codec = 0
	log.cleaner.io.buffer.load.factor = 0.9
	replica.fetch.max.bytes = 1048576
	log.retention.hours = 168
	log.cleaner.delete.retention.ms = 86400000
	log.dirs = /home/tony/projects/openbel/openbel-server/out/kafka-logs
	log.index.size.max.bytes = 10485760
	fetch.purgatory.purge.interval.requests = 1000
	log.retention.minutes = null
	connections.max.idle.ms = 600000
	log.cleaner.min.cleanable.ratio = 0.5
	offsets.commit.timeout.ms = 5000
	offsets.retention.minutes = 1440
	max.connections.per.ip = 2147483647
	log.retention.bytes = -1
	offset.metadata.max.bytes = 4096
	replica.fetch.wait.max.ms = 500
	metrics.num.samples = 2
	leader.imbalance.check.interval.seconds = 300
	port = 9092
	offsets.retention.check.interval.ms = 600000
	log.roll.jitter.ms = null
	reserved.broker.max.id = 1000
	log.cleaner.dedupe.buffer.size = 524288000
	replica.fetch.backoff.ms = 1000
	log.segment.bytes = 1073741824
	advertised.host.name = null
	log.cleaner.io.buffer.size = 524288
	log.dir = /tmp/kafka-logs
	min.insync.replicas = 1
	producer.purgatory.purge.interval.requests = 1000
	controlled.shutdown.retry.backoff.ms = 5000
	socket.receive.buffer.bytes = 102400
	log.segment.delete.delay.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.offset.checkpoint.interval.ms = 60000
	consumer.min.session.timeout.ms = 6000
	num.partitions = 1
	num.io.threads = 8
	leader.imbalance.per.broker.percentage = 10
	num.network.threads = 3
	socket.request.max.bytes = 104857600
	queued.max.requests = 500
	zookeeper.connect = localhost:2181
	offsets.topic.replication.factor = 3
	log.roll.ms = null
	replica.socket.timeout.ms = 30000
	offsets.topic.segment.bytes = 104857600
	replica.high.watermark.checkpoint.interval.ms = 5000
	broker.id = 0
	listeners = null
	log.flush.interval.messages = 9223372036854775807
	log.retention.ms = null
	socket.send.buffer.bytes = 102400
	offsets.commit.required.acks = -1
	log.flush.interval.ms = null
	consumer.max.session.timeout.ms = 30000
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	num.replica.fetchers = 1
	default.replication.factor = 1
	metrics.sample.window.ms = 1000
	advertised.listeners = null
	replica.socket.receive.buffer.bytes = 65536
	auto.leader.rebalance.enable = true
	delete.topic.enable = false
	log.index.interval.bytes = 4096
	host.name = 
	metric.reporters = []
	compression.type = producer
	advertised.port = null
	max.connections.per.ip.overrides = 
	replica.fetch.min.bytes = 1
	log.cleanup.policy = delete
 (kafka.server.KafkaConfig)
[2015-08-13 09:08:07,285] INFO starting (kafka.server.KafkaServer)
[2015-08-13 09:08:07,287] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2015-08-13 09:08:07,465] INFO Loading logs. (kafka.log.LogManager)
[2015-08-13 09:08:07,516] INFO Completed load of log evidence-0 with log end offset 1253856 (kafka.log.Log)
[2015-08-13 09:08:07,527] INFO Logs loading complete. (kafka.log.LogManager)
[2015-08-13 09:08:07,528] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2015-08-13 09:08:07,531] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2015-08-13 09:08:07,580] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2015-08-13 09:08:07,581] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2015-08-13 09:08:07,603] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:08:07,604] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:08:07,794] INFO [ConsumerCoordinator 0]: Starting up. (kafka.coordinator.ConsumerCoordinator)
[2015-08-13 09:08:07,796] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:08:07,798] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:08:07,801] INFO [ConsumerCoordinator 0]: Startup complete. (kafka.coordinator.ConsumerCoordinator)
[2015-08-13 09:08:07,812] INFO [Offset Manager on Broker 0]: Removed 0 expired offsets in 17 milliseconds. (kafka.server.OffsetManager)
[2015-08-13 09:08:07,827] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2015-08-13 09:08:07,880] INFO conflict in /brokers/ids/0 data: {"jmx_port":-1,"timestamp":"1439471287843","endpoints":["PLAINTEXT://localhost.localdomain:9092"],"host":"localhost.localdomain","version":2,"port":9092} stored data: {"jmx_port":-1,"timestamp":"1439471272435","endpoints":["PLAINTEXT://localhost.localdomain:9092"],"host":"localhost.localdomain","version":2,"port":9092} (kafka.utils.ZkUtils$)
[2015-08-13 09:08:07,932] INFO I wrote this conflicted ephemeral node [{"jmx_port":-1,"timestamp":"1439471287843","endpoints":["PLAINTEXT://localhost.localdomain:9092"],"host":"localhost.localdomain","version":2,"port":9092}] at /brokers/ids/0 a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)
[2015-08-13 09:08:13,941] INFO conflict in /brokers/ids/0 data: {"jmx_port":-1,"timestamp":"1439471287843","endpoints":["PLAINTEXT://localhost.localdomain:9092"],"host":"localhost.localdomain","version":2,"port":9092} stored data: {"jmx_port":-1,"timestamp":"1439471272435","endpoints":["PLAINTEXT://localhost.localdomain:9092"],"host":"localhost.localdomain","version":2,"port":9092} (kafka.utils.ZkUtils$)
[2015-08-13 09:08:13,987] INFO I wrote this conflicted ephemeral node [{"jmx_port":-1,"timestamp":"1439471287843","endpoints":["PLAINTEXT://localhost.localdomain:9092"],"host":"localhost.localdomain","version":2,"port":9092}] at /brokers/ids/0 a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)
[2015-08-13 09:08:15,040] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2015-08-13 09:08:15,261] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2015-08-13 09:08:15,382] ERROR [KafkaApi-0] error when handling request Name: TopicMetadataRequest; Version: 0; CorrelationId: 3842; ClientId: rdkafka; Topics: evidence (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 1 larger than available brokers: 0
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:76)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:235)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:461)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:444)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:93)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:444)
	at kafka.server.KafkaApis.handleTopicMetadataRequest(KafkaApis.scala:486)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:59)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2015-08-13 09:08:16,482] ERROR [KafkaApi-0] error when handling request Name: TopicMetadataRequest; Version: 0; CorrelationId: 54; ClientId: rdkafka; Topics: evidence (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 1 larger than available brokers: 0
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:76)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:235)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:461)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:444)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:93)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:444)
	at kafka.server.KafkaApis.handleTopicMetadataRequest(KafkaApis.scala:486)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:59)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2015-08-13 09:08:17,486] ERROR [KafkaApi-0] error when handling request Name: TopicMetadataRequest; Version: 0; CorrelationId: 55; ClientId: rdkafka; Topics: evidence (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 1 larger than available brokers: 0
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:76)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:235)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:461)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:444)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:93)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:444)
	at kafka.server.KafkaApis.handleTopicMetadataRequest(KafkaApis.scala:486)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:59)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2015-08-13 09:08:18,388] ERROR [KafkaApi-0] error when handling request Name: TopicMetadataRequest; Version: 0; CorrelationId: 3844; ClientId: rdkafka; Topics: evidence (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 1 larger than available brokers: 0
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:76)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:235)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:461)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:444)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:93)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:444)
	at kafka.server.KafkaApis.handleTopicMetadataRequest(KafkaApis.scala:486)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:59)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2015-08-13 09:08:19,495] ERROR [KafkaApi-0] error when handling request Name: TopicMetadataRequest; Version: 0; CorrelationId: 57; ClientId: rdkafka; Topics: evidence (kafka.server.KafkaApis)
kafka.admin.AdminOperationException: replication factor: 1 larger than available brokers: 0
	at kafka.admin.AdminUtils$.assignReplicasToBrokers(AdminUtils.scala:76)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:235)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:461)
	at kafka.server.KafkaApis$$anonfun$9.apply(KafkaApis.scala:444)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:93)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:444)
	at kafka.server.KafkaApis.handleTopicMetadataRequest(KafkaApis.scala:486)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:59)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2015-08-13 09:08:19,999] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(localhost.localdomain,9092,PLAINTEXT) (kafka.utils.ZkUtils$)
[2015-08-13 09:08:20,012] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2015-08-13 09:08:20,135] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [evidence,0] (kafka.server.ReplicaFetcherManager)
[2015-08-13 09:08:20,158] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [evidence,0] (kafka.server.ReplicaFetcherManager)
[2015-08-13 09:08:43,550] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2015-08-13 09:08:43,552] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[2015-08-13 09:10:38,001] INFO [Kafka Server 0], Controlled shutdown succeeded (kafka.server.KafkaServer)
[2015-08-13 09:10:38,005] INFO [Socket Server on Broker 0], Shutting down (kafka.network.SocketServer)
[2015-08-13 09:10:38,012] INFO [Socket Server on Broker 0], Shutdown completed (kafka.network.SocketServer)
[2015-08-13 09:10:38,013] INFO [Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2015-08-13 09:10:38,015] INFO [Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2015-08-13 09:10:38,019] INFO [Replica Manager on Broker 0]: Shutting down (kafka.server.ReplicaManager)
[2015-08-13 09:10:38,020] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2015-08-13 09:10:38,022] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2015-08-13 09:10:38,022] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:10:38,031] INFO KafkaConfig values: 
	log.roll.hours = 168
	controlled.shutdown.max.retries = 3
	inter.broker.protocol.version = 0.8.3.X
	log.cleaner.threads = 1
	zookeeper.connection.timeout.ms = 6000
	log.preallocate = false
	offsets.load.buffer.size = 5242880
	security.inter.broker.protocol = PLAINTEXT
	controller.socket.timeout.ms = 30000
	zookeeper.session.timeout.ms = 6000
	log.cleaner.enable = false
	controlled.shutdown.enable = true
	offsets.topic.num.partitions = 50
	num.recovery.threads.per.data.dir = 1
	background.threads = 10
	unclean.leader.election.enable = true
	message.max.bytes = 1000012
	log.cleaner.backoff.ms = 15000
	replica.lag.time.max.ms = 10000
	log.roll.jitter.hours = 0
	auto.create.topics.enable = true
	log.retention.check.interval.ms = 300000
	zookeeper.sync.time.ms = 2000
	offsets.topic.compression.codec = 0
	log.cleaner.io.buffer.load.factor = 0.9
	replica.fetch.max.bytes = 1048576
	log.retention.hours = 168
	log.cleaner.delete.retention.ms = 86400000
	log.dirs = /home/tony/projects/openbel/openbel-server/out/kafka-logs
	log.index.size.max.bytes = 10485760
	fetch.purgatory.purge.interval.requests = 1000
	log.retention.minutes = null
	connections.max.idle.ms = 600000
	log.cleaner.min.cleanable.ratio = 0.5
	offsets.commit.timeout.ms = 5000
	offsets.retention.minutes = 1440
	max.connections.per.ip = 2147483647
	log.retention.bytes = -1
	offset.metadata.max.bytes = 4096
	replica.fetch.wait.max.ms = 500
	metrics.num.samples = 2
	leader.imbalance.check.interval.seconds = 300
	port = 9092
	offsets.retention.check.interval.ms = 600000
	log.roll.jitter.ms = null
	reserved.broker.max.id = 1000
	log.cleaner.dedupe.buffer.size = 524288000
	replica.fetch.backoff.ms = 1000
	log.segment.bytes = 1073741824
	advertised.host.name = null
	log.cleaner.io.buffer.size = 524288
	log.dir = /tmp/kafka-logs
	min.insync.replicas = 1
	producer.purgatory.purge.interval.requests = 1000
	controlled.shutdown.retry.backoff.ms = 5000
	socket.receive.buffer.bytes = 102400
	log.segment.delete.delay.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.offset.checkpoint.interval.ms = 60000
	consumer.min.session.timeout.ms = 6000
	num.partitions = 1
	num.io.threads = 8
	leader.imbalance.per.broker.percentage = 10
	num.network.threads = 3
	socket.request.max.bytes = 104857600
	queued.max.requests = 500
	zookeeper.connect = localhost:2181
	offsets.topic.replication.factor = 3
	log.roll.ms = null
	replica.socket.timeout.ms = 30000
	offsets.topic.segment.bytes = 104857600
	replica.high.watermark.checkpoint.interval.ms = 5000
	broker.id = 0
	listeners = null
	log.flush.interval.messages = 9223372036854775807
	log.retention.ms = null
	socket.send.buffer.bytes = 102400
	offsets.commit.required.acks = -1
	log.flush.interval.ms = null
	consumer.max.session.timeout.ms = 30000
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	num.replica.fetchers = 1
	default.replication.factor = 1
	metrics.sample.window.ms = 1000
	advertised.listeners = null
	replica.socket.receive.buffer.bytes = 65536
	auto.leader.rebalance.enable = true
	delete.topic.enable = false
	log.index.interval.bytes = 4096
	host.name = 
	metric.reporters = []
	compression.type = producer
	advertised.port = null
	max.connections.per.ip.overrides = 
	replica.fetch.min.bytes = 1
	log.cleanup.policy = delete
 (kafka.server.KafkaConfig)
[2015-08-13 09:10:38,081] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:10:38,081] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:10:38,081] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:10:38,137] INFO starting (kafka.server.KafkaServer)
[2015-08-13 09:10:38,139] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2015-08-13 09:10:38,151] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:10:38,152] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:10:38,162] INFO [Replica Manager on Broker 0]: Shut down completely (kafka.server.ReplicaManager)
[2015-08-13 09:10:38,162] INFO Shutting down. (kafka.log.LogManager)
[2015-08-13 09:10:38,183] INFO Shutdown complete. (kafka.log.LogManager)
[2015-08-13 09:10:38,184] INFO [ConsumerCoordinator 0]: Shutting down. (kafka.coordinator.ConsumerCoordinator)
[2015-08-13 09:10:38,185] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:10:38,289] INFO Loading logs. (kafka.log.LogManager)
[2015-08-13 09:10:38,336] INFO Completed load of log evidence-0 with log end offset 1253856 (kafka.log.Log)
[2015-08-13 09:10:38,344] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:10:38,344] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:10:38,345] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:10:38,350] INFO Logs loading complete. (kafka.log.LogManager)
[2015-08-13 09:10:38,351] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2015-08-13 09:10:38,357] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2015-08-13 09:10:38,422] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2015-08-13 09:10:38,423] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2015-08-13 09:10:38,455] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:10:38,456] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:10:38,544] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:10:38,544] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:10:38,546] INFO [ConsumerCoordinator 0]: Shutdown complete. (kafka.coordinator.ConsumerCoordinator)
[2015-08-13 09:10:38,561] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[2015-08-13 09:10:38,698] INFO [ConsumerCoordinator 0]: Starting up. (kafka.coordinator.ConsumerCoordinator)
[2015-08-13 09:10:38,707] INFO [ConsumerCoordinator 0]: Startup complete. (kafka.coordinator.ConsumerCoordinator)
[2015-08-13 09:10:38,708] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:10:38,710] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-13 09:10:38,710] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2015-08-13 09:10:38,713] INFO [Offset Manager on Broker 0]: Removed 0 expired offsets in 20 milliseconds. (kafka.server.OffsetManager)
[2015-08-13 09:10:38,736] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2015-08-13 09:10:38,825] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(localhost.localdomain,9092,PLAINTEXT) (kafka.utils.ZkUtils$)
[2015-08-13 09:10:38,842] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2015-08-13 09:10:39,025] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2015-08-13 09:10:39,210] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [evidence,0] (kafka.server.ReplicaFetcherManager)
[2015-08-13 09:10:39,244] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [evidence,0] (kafka.server.ReplicaFetcherManager)
[2015-08-13 09:11:02,269] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2015-08-13 09:11:02,270] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
